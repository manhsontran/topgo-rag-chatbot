"""
FastAPI Main Application - REST API for TopGo RAG Chatbot
"""
import os
import sys
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Load environment variables from project root
load_dotenv(dotenv_path=project_root / '.env')

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

from src.api.models import (
    ChatRequest, ChatResponse, RestaurantInfo,
    SearchRequest, SearchResponse,
    RecommendationRequest, RecommendationResponse,
    HealthResponse, ErrorResponse,
    RestaurantType, PriceRange
)
from src.rag.pipeline import RAGPipeline
from src.embeddings.search_engine import RestaurantSearchEngine
from src.llm.ollama_client import OllamaClient

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ========== FASTAPI APP SETUP ==========

app = FastAPI(
    title="TopGo RAG Chatbot API",
    description="TopGo RAG Chatbot API - He thong goi y nha hang thong minh voi AI. Chat voi AI, tim kiem semantic, goi y ca nhan hoa. Du lieu: 159 nha hang tu TopGo.vn (Ha Noi). LLM: qwen2:7b (Vietnamese-optimized)",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_tags=[
        {
            "name": "chat",
            "description": "üí¨ Chat endpoints - Tr√≤ chuy·ªán v·ªõi AI chatbot"
        },
        {
            "name": "search",
            "description": "üîç Search endpoints - T√¨m ki·∫øm nh√† h√†ng"
        },
        {
            "name": "recommendations",
            "description": "üéØ Recommendation endpoints - G·ª£i √Ω nh√† h√†ng"
        },
        {
            "name": "health",
            "description": "‚ù§Ô∏è Health endpoints - Ki·ªÉm tra h·ªá th·ªëng"
        }
    ]
)

# ========== CORS MIDDLEWARE ==========

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # TODO: Change to specific origins in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== GLOBAL STATE ==========

class AppState:
    """Global application state"""
    rag_pipeline: Optional[RAGPipeline] = None
    search_engine: Optional[RestaurantSearchEngine] = None
    ollama_client: Optional[OllamaClient] = None
    is_initialized: bool = False
    error_message: Optional[str] = None

state = AppState()

# ========== STARTUP & SHUTDOWN EVENTS ==========

@app.on_event("startup")
async def startup_event():
    """Initialize RAG pipeline and components on startup"""
    logger.info("üöÄ Starting TopGo RAG Chatbot API...")
    
    try:
        # Initialize search engine
        logger.info("üìö Loading vector database...")
        state.search_engine = RestaurantSearchEngine()
        logger.info(f"‚úÖ Search engine loaded with {state.search_engine.collection.count()} restaurants")
        
        # Initialize RAG pipeline with Ollama (Local LLM)
        logger.info("üîß Initializing RAG pipeline...")
        logger.info("ü§ñ Using Ollama (Local LLM - Free, No API Keys Required)")
        
        state.rag_pipeline = RAGPipeline(
            model="qwen2:1.5b",  # Fast, Vietnamese-optimized
            ollama_url="http://localhost:11434",
            search_top_k=5
        )
        logger.info("‚úÖ RAG pipeline initialized")
        
        state.is_initialized = True
        logger.info("‚úÖ API startup complete - Ready to serve requests!")
        
    except Exception as e:
        logger.error(f"‚ùå Error during startup: {str(e)}")
        state.error_message = str(e)
        state.is_initialized = False
        # Don't raise - allow API to start in degraded mode


@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    logger.info("üëã Shutting down TopGo RAG Chatbot API...")
    state.is_initialized = False


# ========== EXCEPTION HANDLERS ==========

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Handle HTTP exceptions"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.__class__.__name__,
            "message": exc.detail,
            "details": None
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Handle general exceptions"""
    logger.error(f"Unhandled exception: {str(exc)}", exc_info=True)
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "InternalServerError",
            "message": "ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën. Vui l√≤ng th·ª≠ l·∫°i sau.",
            "details": {"exception": str(exc)}
        }
    )


# ========== HELPER FUNCTIONS ==========

def check_initialized():
    """Check if the app is properly initialized"""
    if not state.is_initialized:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"H·ªá th·ªëng ch∆∞a s·∫µn s√†ng. L·ªói: {state.error_message or 'Unknown error'}"
        )


def format_restaurant_info(result: Dict[str, Any]) -> RestaurantInfo:
    """Convert search result to RestaurantInfo model"""
    return RestaurantInfo(
        name=result.get('name', 'Unknown'),
        type=result.get('type', 'other'),
        address=result.get('address', ''),
        district=result.get('district', ''),
        price_range=result.get('price_range', 'moderate'),
        phone=result.get('phone'),
        description=result.get('description'),
        url=result.get('url'),
        similarity_score=result.get('similarity_score')
    )


# ========== HEALTH ENDPOINTS ==========

@app.get("/", tags=["health"])
async def root():
    """Root endpoint - API info"""
    return {
        "message": "TopGo RAG Chatbot API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse, tags=["health"])
async def health_check():
    """
    Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng
    
    Returns:
        - Tr·∫°ng th√°i API, database, LLM
        - S·ªë l∆∞·ª£ng nh√† h√†ng
        - Danh s√°ch models c√≥ s·∫µn
    """
    try:
        # Check database
        db_status = "disconnected"
        total_restaurants = 0
        if state.search_engine:
            try:
                total_restaurants = state.search_engine.collection.count()
                db_status = "connected"
            except Exception as e:
                logger.error(f"Database check failed: {e}")
                db_status = "error"
        
        # Check LLM
        llm_status = "disconnected"
        available_models = []
        if state.ollama_client:
            try:
                if state.ollama_client.check_connection():
                    llm_status = "connected"
                    available_models = state.ollama_client.list_models()
            except Exception as e:
                logger.error(f"LLM check failed: {e}")
                llm_status = "error"
        
        # Overall status
        overall_status = "healthy" if state.is_initialized else "degraded"
        
        return HealthResponse(
            status=overall_status,
            version="1.0.0",
            database_status=db_status,
            llm_status=llm_status,
            total_restaurants=total_restaurants,
            available_models=available_models
        )
        
    except Exception as e:
        logger.error(f"Health check error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Health check failed: {str(e)}"
        )


# ========== CHAT ENDPOINTS ==========

@app.post("/api/chat", response_model=ChatResponse, tags=["chat"])
async def chat(request: ChatRequest):
    """
    üí¨ Chat v·ªõi AI chatbot
    
    G·ª≠i c√¢u h·ªèi b·∫±ng ti·∫øng Vi·ªát v√† nh·∫≠n c√¢u tr·∫£ l·ªùi t·ª´ AI k√®m danh s√°ch nh√† h√†ng ph√π h·ª£p.
    
    **Modes:**
    - `use_rag=True`: Full RAG (Retrieval + AI Generation) - C√¢u tr·∫£ l·ªùi t·ª± nhi√™n
    - `use_rag=False`: Search only - Ch·ªâ t√¨m ki·∫øm v√† li·ªát k√™
    
    **Filters:**
    - `type`: restaurant/bar/karaoke/cafe
    - `district`: Cau Giay/Dong Da/Hoan Kiem/etc
    - `price`: cheap/moderate/expensive
    
    **Examples:**
    - "T√¨m qu√°n bar c√≥ view ƒë·∫πp ·ªü T√¢y H·ªì"
    - "Nh√† h√†ng Vi·ªát Nam b√¨nh d√¢n cho sinh vi√™n"
    - "Karaoke sang tr·ªçng ph√π h·ª£p h·ªçp l·ªõp"
    """
    check_initialized()
    
    try:
        logger.info(f"Chat request: {request.query[:100]}...")
        
        # Call RAG pipeline - answer() t·ª± ƒë·ªông classify query
        if request.use_rag:
            # Full RAG mode v·ªõi LLM classification
            if not state.rag_pipeline:
                raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
            result = state.rag_pipeline.answer(
                query=request.query,
                top_k=request.top_k,
                filters=request.filters
            )
            
            query_type = "rag"
            answer = result['answer']
            llm_model = state.rag_pipeline.model if state.rag_pipeline else 'gemini-2.0-flash'
            
        else:
            # Search-only mode (no LLM)
            if not state.rag_pipeline:
                raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
            results = state.rag_pipeline.retrieve(
                query=request.query,
                top_k=request.top_k,
                filters=request.filters
            )
            
            query_type = "search"
            llm_model = None
            
            # Format simple answer
            if results:
                answer = f"T√¨m th·∫•y {len(results)} nh√† h√†ng ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n:\n\n"
                for i, r in enumerate(results, 1):
                    answer += f"{i}. **{r['name']}** - {r['address']}\n"
                    if r.get('description'):
                        answer += f"   {r['description'][:100]}...\n"
            else:
                answer = "Xin l·ªói, kh√¥ng t√¨m th·∫•y nh√† h√†ng ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n."
            
            result = {'sources': results}
        
        # Format restaurants
        restaurants = [
            format_restaurant_info(r) 
            for r in result.get('sources', [])
        ]
        
        return ChatResponse(
            answer=answer,
            restaurants=restaurants,
            sources_count=len(restaurants),
            query_type=query_type,
            llm_model=llm_model
        )
        
    except Exception as e:
        logger.error(f"Chat error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"L·ªói khi x·ª≠ l√Ω chat: {str(e)}"
        )


# ========== SEARCH ENDPOINTS ==========

@app.post("/api/search", response_model=SearchResponse, tags=["search"])
async def search(request: SearchRequest):
    """
    üîç T√¨m ki·∫øm nh√† h√†ng
    
    Semantic search v·ªõi b·ªô l·ªçc chi ti·∫øt.
    
    **Parameters:**
    - `query`: T·ª´ kh√≥a t√¨m ki·∫øm (VD: "l·∫©u Th√°i", "view h·ªì T√¢y")
    - `top_k`: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ (1-50)
    - `restaurant_type`: Lo·∫°i h√¨nh (restaurant/bar/karaoke/cafe)
    - `district`: Qu·∫≠n/huy·ªán
    - `price_range`: Kho·∫£ng gi√° (cheap/moderate/expensive)
    - `min_score`: ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng t·ªëi thi·ªÉu (0-1)
    
    **Returns:**
    - Danh s√°ch nh√† h√†ng ƒë∆∞·ª£c s·∫Øp x·∫øp theo ƒë·ªô ph√π h·ª£p
    """
    check_initialized()
    
    try:
        logger.info(f"Search request: {request.query}")
        
        # Build filters
        filters = {}
        if request.restaurant_type:
            filters['type'] = request.restaurant_type.value
        if request.district:
            filters['district'] = request.district
        if request.price_range and request.price_range != PriceRange.all:
            filters['price'] = request.price_range.value
        
        # Search
        if not state.search_engine:
            raise HTTPException(status_code=503, detail="Search engine not initialized")
        results = state.search_engine.search(
            query=request.query,
            n_results=request.top_k,
            filters=filters if filters else None
        )
        
        # Filter by minimum score
        filtered_results = [
            r for r in results 
            if r.get('similarity_score', 0) >= request.min_score
        ]
        
        # Format results
        restaurants = [format_restaurant_info(r) for r in filtered_results]
        
        return SearchResponse(
            query=request.query,
            restaurants=restaurants,
            total_found=len(restaurants),
            filters_applied=filters
        )
        
    except Exception as e:
        logger.error(f"Search error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"L·ªói khi t√¨m ki·∫øm: {str(e)}"
        )


# ========== RECOMMENDATION ENDPOINTS ==========

@app.post("/api/recommendations", response_model=RecommendationResponse, tags=["recommendations"])
async def get_recommendations(request: RecommendationRequest):
    """
    üéØ Nh·∫≠n g·ª£i √Ω nh√† h√†ng c√° nh√¢n h√≥a
    
    D·ª±a tr√™n d·ªãp, s·ªë ng∆∞·ªùi, ng√¢n s√°ch v√† s·ªü th√≠ch ƒë·ªÉ g·ª£i √Ω nh√† h√†ng ph√π h·ª£p.
    
    **Parameters:**
    - `occasion`: D·ªãp (sinh nh·∫≠t, h·∫πn h√≤, h·ªçp l·ªõp, gia ƒë√¨nh, c√¥ng ty, etc)
    - `group_size`: S·ªë ng∆∞·ªùi
    - `budget_per_person`: Ng√¢n s√°ch/ng∆∞·ªùi (VND)
    - `district`: Khu v·ª±c ∆∞u ti√™n
    - `preferences`: S·ªü th√≠ch (view ƒë·∫πp, y√™n tƒ©nh, parking, etc)
    
    **Examples:**
    ```json
    {
        "occasion": "h·∫πn h√≤",
        "group_size": 2,
        "budget_per_person": 500000,
        "district": "Tay Ho",
        "preferences": ["view h·ªì T√¢y", "l√£ng m·∫°n"]
    }
    ```
    """
    check_initialized()
    
    try:
        logger.info(f"Recommendation request: {request.occasion}, {request.group_size} people")
        
        # Build query from criteria
        query_parts = []
        
        if request.occasion:
            occasion_keywords = {
                "sinh nh·∫≠t": "ph√π h·ª£p sinh nh·∫≠t, kh√¥ng gian vui v·∫ª",
                "h·∫πn h√≤": "l√£ng m·∫°n, view ƒë·∫πp, ri√™ng t∆∞",
                "h·ªçp l·ªõp": "ph√≤ng ri√™ng, karaoke, nh√≥m ƒë√¥ng",
                "gia ƒë√¨nh": "gia ƒë√¨nh, tr·∫ª em, tho·∫£i m√°i",
                "c√¥ng ty": "chuy√™n nghi·ªáp, ph√≤ng VIP, h·ªôi ngh·ªã"
            }
            query_parts.append(occasion_keywords.get(request.occasion.lower(), request.occasion))
        
        if request.preferences:
            query_parts.extend(request.preferences)
        
        query = " ".join(query_parts) if query_parts else "nh√† h√†ng t·ªët"
        
        # Determine filters
        filters = {}
        
        # Price filter based on budget
        if request.budget_per_person:
            if request.budget_per_person < 100000:
                filters['price'] = 'cheap'
            elif request.budget_per_person < 300000:
                filters['price'] = 'moderate'
            else:
                filters['price'] = 'expensive'
        
        if request.district:
            filters['district'] = request.district
        
        # Determine restaurant type from occasion
        if request.occasion and "karaoke" in request.occasion.lower():
            filters['type'] = 'karaoke'
        elif request.occasion and any(kw in request.occasion.lower() for kw in ["bar", "r∆∞·ª£u", "cocktail"]):
            filters['type'] = 'bar'
        
        # Search
        if not state.search_engine:
            raise HTTPException(status_code=503, detail="Search engine not initialized")
        n_results = min(request.group_size, 10) if request.group_size else 5
        results = state.search_engine.search(
            query=query,
            n_results=n_results,
            filters=filters if filters else None
        )
        
        # Format results
        recommendations = [format_restaurant_info(r) for r in results]
        
        # Generate suggestion reason
        reason_parts = []
        if request.occasion:
            reason_parts.append(f"ph√π h·ª£p cho {request.occasion}")
        if request.group_size:
            reason_parts.append(f"{request.group_size} ng∆∞·ªùi")
        if request.budget_per_person:
            budget_text = f"{request.budget_per_person:,}ƒë/ng∆∞·ªùi"
            reason_parts.append(f"ng√¢n s√°ch {budget_text}")
        if request.district:
            reason_parts.append(f"t·∫°i {request.district}")
        
        suggestion_reason = "C√°c nh√† h√†ng n√†y " + ", ".join(reason_parts) if reason_parts else "G·ª£i √Ω nh√† h√†ng ph√π h·ª£p"
        
        return RecommendationResponse(
            recommendations=recommendations,
            criteria_used={
                "occasion": request.occasion,
                "group_size": request.group_size,
                "budget_per_person": request.budget_per_person,
                "district": request.district,
                "preferences": request.preferences
            },
            suggestion_reason=suggestion_reason,
            total_recommendations=len(recommendations)
        )
        
    except Exception as e:
        logger.error(f"Recommendation error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"L·ªói khi t·∫°o g·ª£i √Ω: {str(e)}"
        )


# ========== RUN SERVER ==========

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
